{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLnPGDIysPwf/Ofwnpfubl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maricelp02/computoenlanube/blob/main/Prueba_im%C3%A1genes_MS_Azure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYaJN-kioMOm",
        "outputId": "49711eee-3e7d-405e-d405-dbe679d6a026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"faceRectangle\": {\"top\": 159, \"left\": 118, \"width\": 94, \"height\": 94}}, {\"faceRectangle\": {\"top\": 111, \"left\": 492, \"width\": 90, \"height\": 90}}, {\"faceRectangle\": {\"top\": 153, \"left\": 18, \"width\": 84, \"height\": 84}}, {\"faceRectangle\": {\"top\": 166, \"left\": 386, \"width\": 81, \"height\": 81}}, {\"faceRectangle\": {\"top\": 158, \"left\": 235, \"width\": 76, \"height\": 76}}, {\"faceRectangle\": {\"top\": 163, \"left\": 323, \"width\": 68, \"height\": 68}}]\n"
          ]
        }
      ],
      "source": [
        "import json, os, requests\n",
        "\n",
        "#Asignar a una variable la clave para acceder a la API\n",
        "subscription_key = \"66dd7d7abfaf423fa04080f8d44bf2c2\"\n",
        "\n",
        "#Asignar a una variable la URL de la imagen de prueba que se estará usando\n",
        "face_api_url = \"https://facerecognitionmna25.cognitiveservices.azure.com/\" + '/face/v1.0/detect'\n",
        "\n",
        "#Asignar a una variable la URL del API Endpoint, es decir, la URL del recurso de Azure que estaremos usando\n",
        "image_url = \"https://raw.githubusercontent.com/ecendejas/imgMNA/main/faces.jpg\"\n",
        "\n",
        "#Se llena la cabecera que usaremos para pasar la clave para autenticarse en Microsoft Azure\n",
        "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
        "\n",
        "# Desactivar returnFaceId  porque no tenemos acceso a estas opciones.\n",
        "#returnFaceId devuelve un ID para cada cara única encontrada\n",
        "#returnFaceLandmarks devuelve las coordenadas de los diferentes atributos de la cara\n",
        "params = {\n",
        "    'returnFaceId': 'False', \n",
        "    'returnFaceLandmarks': 'false', \n",
        "    #'returnFaceAttributes':'age, gender beadPose,smile, facialBair, glasses, emotion',\n",
        "}\n",
        "\n",
        "#Enviar el request por medio de un post, asignando como argumento cada uno de los parámetros definidos anteriormente\n",
        "\n",
        "response = requests.post(face_api_url, params=params, headers=headers, json={\"url\":image_url})\n",
        "\n",
        "#Imprimir el resultado\n",
        "print(json.dumps(response.json()))\n",
        "\n",
        "\n"
      ]
    }
  ]
}